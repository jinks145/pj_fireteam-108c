{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e22cafc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pprint\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as pl\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "from surprise.prediction_algorithms import SVD, KNNBasic, KNNBaseline\n",
    "np.set_printoptions(threshold=20)\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98d1b4a1-86a2-4fd0-b6fc-01eda6f0683a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#FUNCTION TO CONVERT CSV TO DATAFRAME\n",
    "#converts and reduces dataframe to usable data\n",
    "def csv_to_df(string1, string2):    \n",
    "    df = pd.read_csv(string1)\n",
    "\n",
    "    df_book = pd.read_csv(string2)\n",
    "\n",
    "    category_array = df_book['categories'].unique()\n",
    "\n",
    "    category_array.size\n",
    "    #print('\\n'.join(category_array.values))\n",
    "\n",
    "\n",
    "\n",
    "    #Preprocessing/Data Cleaning\n",
    "    df_ratings = df\n",
    "\n",
    "    drop_columns = [\"Price\", \"profileName\", \"review/time\", \"review/summary\", \"review/helpfulness\", \"review/text\"]\n",
    "\n",
    "    books_ratings_cleaned = df_ratings.drop(drop_columns, axis=1)\n",
    "\n",
    "    #Create Dictionary Key for Unique ID:Book\n",
    "    book_dict = dict()\n",
    "    for row in books_ratings_cleaned.itertuples():\n",
    "        if row[1] not in book_dict:\n",
    "            book_dict[row[1]] = [row[2],0]\n",
    "\n",
    "        book_dict[row[1]][1] +=1\n",
    "\n",
    "\n",
    "    drop_columns = [\"Title\", \"Price\", \"profileName\", \"review/time\", \"review/summary\", \"review/helpfulness\", \"review/text\"]\n",
    "\n",
    "    books_ratings_cleaned = df_ratings.drop(drop_columns, axis=1)\n",
    "\n",
    "    #books_ratings_cleaned\n",
    "\n",
    "    books_ratings_cleaned['User_id'].isna()\n",
    "\n",
    "    sum(books_ratings_cleaned['User_id'].isna())\n",
    "\n",
    "    books_ratings_cleaned = books_ratings_cleaned[books_ratings_cleaned['User_id'].notna()]\n",
    "\n",
    "    return books_ratings_cleaned, book_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d062e161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to convert data frame to numpy matrix\n",
    "def Convert_to_Matrix(matrix):\n",
    "    #convert Dictionary Key into Sparse Matrix With users as Columns, Books as rows\n",
    "    test = pd.DataFrame.from_dict(matrix)\n",
    "\n",
    "    test.head()\n",
    "\n",
    "    #take Matrix Transpose\n",
    "    test_transpose = test.transpose()\n",
    "\n",
    "    #populate NaN's as zeroes\n",
    "    A_transpose = test_transpose.fillna(0)\n",
    "\n",
    "    return A_transpose\n",
    "\n",
    "#function to perform LU factorization on numpy matrix\n",
    "def LU_Factorization(matrix):\n",
    "    #A = PLU FACTORIZATION\n",
    "    P, L, U = scipy.linalg.lu(matrix)\n",
    "\n",
    "    A_test = np.matmul(P, np.matmul(L, U))\n",
    "\n",
    "    #Test for Accuracy\n",
    "    print(np.allclose(matrix, A_test))\n",
    "    \n",
    "    return P, L, U\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6058e9-3551-4b8b-8fa3-2d5e5e039bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLLABORATIVE FILTERING COSINE SIMILARITY FUNCTION\n",
    "#finding similar users by using cosine similarity algorithm\n",
    "def find_similar(user_1, k):\n",
    "    allusers = A.values\n",
    "    denominator1 = np.sqrt(sum([np.square(x) for x in user_1]))\n",
    "    \n",
    "    #performs cosine similarity algorithm on vectors (users)\n",
    "    cosinesimilarity = [(user_1.name,1)]\n",
    "    i=1\n",
    "    for user in tqdm(allusers[1:]):\n",
    "        numerator = [x*y for x,y in zip(user_1.values, user)]\n",
    "        denominator2 = np.sqrt(sum([np.square(x) for x in user]))\n",
    "        costheta = sum(numerator) / (denominator1 * denominator2)\n",
    "        cosinesimilarity.append((A.index[i],costheta))\n",
    "        i+=1\n",
    "    \n",
    "    #sort the results\n",
    "    cosinesimilarity.sort(key = lambda x: x[1], reverse = True)\n",
    "    \n",
    "    #combine sorted results\n",
    "    similar10users = cosinesimilarity[0:k]\n",
    "    \n",
    "    #output results of sorted similar users\n",
    "    for i in range(0,k):\n",
    "        print(similar10users[i])\n",
    "    \n",
    "    #place similar users into a data frame\n",
    "    top10usersdf = pd.DataFrame()\n",
    "    for user in similar10users:\n",
    "        top10usersdf = top10usersdf.append(A.loc[user[0]])\n",
    "    top10usersdf['costheta'] = [user[1] for user in similar10users]\n",
    "    \n",
    "    #to be used in calculation of distance/similarity for recommendation\n",
    "    all_values = top10usersdf.values\n",
    "\n",
    "    return top10usersdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "409dea7e-c6d5-40ac-aa34-d6c5e6f28d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper methods for getting subsets of users that have more data, reducing the sparcity of matrix\n",
    "# when experimenting with the dataset\n",
    "def get_most_frequent_users(count, source_frame):\n",
    "    assert isinstance(count, int), \"Argument must be an integer\"\n",
    "    assert count > 0, \"Argument must be a positive integer\"\n",
    "    \n",
    "    user_occurences = source_frame['User_id'].value_counts()\n",
    "    \n",
    "    assert count < user_occurences.count(), \"Requested more data then we have...not tiny\"\n",
    "    \n",
    "    return user_occurences.head(count).index.to_list()\n",
    "\n",
    "def get_users_with_minimal_ratings(rated, source_frame):\n",
    "    assert isinstance(rated, int), \"Argument must be an integer\"\n",
    "    assert rated > 0, \"Argument must be a positive integer\"\n",
    "    \n",
    "    # Get a series mapping user ids to their occurences in the data frame\n",
    "    user_occurences = source_frame['User_id'].value_counts()\n",
    "    return user_occurences[user_occurences > rated].index.to_list()\n",
    "\n",
    "def get_training_data(ratio: float, source_frame):\n",
    "    assert isinstance(ratio, float), \"Ratio must be a float\"\n",
    "    assert 0.0 < ratio < 1.0, \"Ratio must be in [0, 1]\"\n",
    "    \n",
    "    # we want to ensure that our test data is built from good users, users with\n",
    "    # less then 10 ratings are considered un-testable.\n",
    "    # FILTER USERS BY NUMBER OF REVIEWS PER USER HERE\n",
    "    good_users = get_users_with_minimal_ratings(10, source_frame)\n",
    "    \n",
    "    # Randomize the order of ratings for users in our good users set.\n",
    "    good_users_ratings = source_frame[source_frame['User_id'].isin(good_users)].sample(frac=1)\n",
    "    \n",
    "    total_count = good_users_ratings.shape[0]\n",
    "    training_data_count = int(total_count * ratio)\n",
    "    \n",
    "    training_data = pivot_rating_to_user_frame(good_users_ratings[0:training_data_count])\n",
    "    test_data = pivot_rating_to_user_frame(good_users_ratings[training_data_count:])\n",
    "    \n",
    "    return training_data, test_data\n",
    "\n",
    "def pivot_rating_to_user_frame(source_frame):\n",
    "    new_data = dict()\n",
    "    for _, row in tqdm(source_frame.iterrows(), total=source_frame.shape[0]):\n",
    "        (user_id, book_id, score) = row\n",
    "        if user_id not in new_data:\n",
    "            new_data[user_id] = defaultdict(lambda: np.nan)\n",
    "        new_data[user_id][book_id] = score\n",
    "        \n",
    "    return pd.DataFrame.from_dict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "148748ee-dc63-48dc-9a87-8dbc26acc534",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_ratings_cleaned, book_dict = csv_to_df(\"Books_rating.csv\", \"books_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff51e7f0-2d4f-480a-ace2-a2d5e68cd9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id              2438213\n",
       "User_id         2438213\n",
       "review/score    2438213\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_ratings_cleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42867cfe-a0b4-4465-95cc-38c5b9d3bfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Id</th>\n",
       "      <th>review/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>1882931173</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          User_id          Id  review/score\n",
       "0   AVCGYZL8FQQTD  1882931173           4.0\n",
       "1  A30TK6U7DNS82R  0826414346           5.0\n",
       "2  A3UH4UZ4RSVO82  0826414346           5.0\n",
       "3  A2MVUWT453QH61  0826414346           4.0\n",
       "4  A22X4XUPKF66MR  0826414346           4.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_titles = [\"User_id\",\"Id\", \"review/score\"]\n",
    "Books_ratings_cleaned = books_ratings_cleaned.reindex(columns=columns_titles)\n",
    "\n",
    "#Books_ratings_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b85a17-c2d3-42f8-bb18-09cfa0bf12fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3760/3760 [00:00<00:00, 11720.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 1254/1254 [00:00<00:00, 13137.09it/s]\n"
     ]
    }
   ],
   "source": [
    "#EXCUTE ME PLEASE FOR REAL IM DYING\n",
    "#LIKE REALLY, RUN ME\n",
    "training_data, test_data = get_training_data(0.75, books_ratings_cleaned.sample(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a464bc5-0645-4414-a404-368f6fc1c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = training_data.fillna(0)\n",
    "\n",
    "#A.head()\n",
    "\n",
    "#A = A.to_numpy()\n",
    "\n",
    "#np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "931018ef-d7a9-4d39-8b0f-8750e3d5b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in values as Surprise dataset\n",
    "#reader = Reader(rating_scale=(1, 5))\n",
    "#data = Dataset.load_from_df(training_data, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7be831-fc9b-40d3-b600-ed55aea6d8cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#A_similar = find_similar(A.iloc[0],10)\n",
    "\n",
    "#A_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2de14-b98c-4c25-9377-c8c928f053cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THIS TO CHECK BOOK ID\n",
    "#print(book_dict.get('1557424470'))\n",
    "#A_similar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "478c4056-4320-4c60-8e6f-5bd94d34c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERBOOK = Books_ratings_cleaned.head(50000)\n",
    "\n",
    "#USERBOOK.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38d72dcf-503b-44bc-95f4-d7111da00ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(USERBOOK, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6a8fe62-0dc6-40f3-bd80-f58fdaf722d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0855  1.0751  1.0851  1.0836  1.0891  1.0837  0.0047  \n",
      "MAE (testset)     0.8225  0.8153  0.8203  0.8243  0.8268  0.8218  0.0039  \n",
      "Fit time          0.75    0.63    0.73    0.74    0.79    0.73    0.05    \n",
      "Test time         0.08    0.08    0.07    0.07    0.08    0.08    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.08553103, 1.07509269, 1.08513763, 1.08358879, 1.08909244]),\n",
       " 'test_mae': array([0.82247379, 0.81529567, 0.82034333, 0.82426678, 0.82681063]),\n",
       " 'fit_time': (0.7490639686584473,\n",
       "  0.6280405521392822,\n",
       "  0.7321815490722656,\n",
       "  0.7377645969390869,\n",
       "  0.7922866344451904),\n",
       " 'test_time': (0.07548046112060547,\n",
       "  0.08153748512268066,\n",
       "  0.07371354103088379,\n",
       "  0.0736551284790039,\n",
       "  0.07596135139465332)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1ad8e39-828f-4a7a-aecd-df77908b11e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='A30TK6U7DNS82R', iid='0826414346', r_ui=None, est=4.99653471821967, details={'was_impossible': False})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data.build_full_trainset()\n",
    "svd = SVD(n_factors=5000, reg_all=0.05)\n",
    "svd.fit(dataset)\n",
    "svd.predict('A30TK6U7DNS82R', '0826414346')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128987d-1e2d-4b5f-9e7b-548bf0ce3a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
