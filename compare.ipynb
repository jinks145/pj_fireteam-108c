{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import AutoEncoder\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_data:\n",
    "\tsample = pd.read_csv('predictions.csv')\n",
    "\tres = { k: v.get([\"book_id\", \"rating\"]) for k, v in sample.groupby('user_id')}\n",
    "\tsample_matrix = pd.DataFrame(index= res.keys(), columns = sample['book_id'].unique())\n",
    "\tsample_matrix.to_csv('sample_matrix.csv.gzip', index=True, columns=sample_matrix.columns, chunksize=1000, compression='gzip')\n",
    "\tfor k, v in res.items():\n",
    "\t\tt = v.reset_index(drop=True).transpose()\n",
    "\t\tsample_matrix.loc[k][t.loc[\"book_id\"]] = t.loc[\"rating\"]\n",
    "else:\n",
    "\tsample_matrix = pd.read_csv('sample_matrix.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not training:\n",
    "\tmodel = torch.load('sample_model/sample_model_k=32.pt')\n",
    "\tmodel.load_state_dict(torch.load('sample_model/sample_model_k_weights_32.pt'))\n",
    "else:\n",
    "\tbottleneck = 32\n",
    "\ttensors = torch.tensor(sample_matrix.T.to_numpy(), dtype=torch.float32, device=device)\n",
    "\tbatch_size = 32 \n",
    "\ttrain = TensorDataset(tensors)\n",
    "\tbatches = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\tmodel = AutoEncoder(sample_matrix.shape[1], bottleneck)\n",
    "\tepochs, losses = model.fit(batches, n_epochs=1000, lr=0.001, patience=10)\n",
    "\tpd.DataFrame({\"epochs\": epochs, \"training losses\": losses}).to_csv(f'models/training_loss/{bottleneck}.csv')\n",
    "\n",
    "\ttorch.save(model, f'sample_model_k={bottleneck}.pt')\n",
    "\ttorch.save(model.state_dict(), f'sample_model_k_weights_{bottleneck}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_test_model(model: nn.Module, mask_fraction: float, row: torch.Tensor, device: torch.device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Identify non-zero elements in the row\n",
    "        non_zero_indices = row.nonzero(as_tuple=True)[0]\n",
    "\n",
    "        # Create a mask for the non-zero elements\n",
    "        mask = torch.rand(len(non_zero_indices)).to(device) < mask_fraction\n",
    "\n",
    "        # Apply the mask to the row\n",
    "        masked_row = row.clone().to(device)\n",
    "        masked_row[non_zero_indices[mask]] = 0\n",
    "\n",
    "        # Get the model's predictions\n",
    "        predictions = model(masked_row)\n",
    "\n",
    "        # Calculate the loss only for the masked values\n",
    "        loss = criterion(predictions[non_zero_indices[mask]], row[non_zero_indices[mask]])\n",
    "\n",
    "        # Optionally, return the predictions and mask for further analysis\n",
    "        return predictions.cpu().numpy(), mask.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sample_model(model: AutoEncoder, sample:pd.DataFrame, device: torch.device):\n",
    "    model.eval()\n",
    "    # sample = interaction_matrix.sample(sample_size, random_state=42)\n",
    "    \n",
    "    # Convert the sample DataFrame to a tensor\n",
    "    sample_tensor = torch.tensor(sample.to_numpy(), dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Test the model on each row of the sample\n",
    "    # tested = sample.apply(lambda row: mask_test_model(model, 0.2, torch.tensor(row.to_numpy(), dtype=torch.float32, device=device), device)[0], axis=1)\n",
    "    tested = []\n",
    "    for row in sample.iterrows():\n",
    "        prediction = mask_test_model(model, 0.2, torch.tensor(row[1].to_numpy(), dtype=torch.float32, device=device), device)[0]\n",
    "        # display(prediction)\n",
    "        prediction = pd.DataFrame(prediction)\n",
    "        tested.append(prediction)\n",
    "    \n",
    "\n",
    "    tested = pd.concat(tested, axis=1)\n",
    "    tested.index = sample.columns\n",
    "    tested.columns = sample.index\n",
    "\n",
    "    # Calculate the Frobenius norm of the difference\n",
    "    # calculate the rmse\n",
    "    \n",
    "    # loss = linalg.norm(sample.to_numpy() - tested.to_numpy().T, ord='fro')\n",
    "    mse = np.mean((sample.to_numpy() - tested.to_numpy().T)**2)\n",
    "    loss = np.sqrt(mse)\n",
    "    \n",
    "    return loss, tested.T, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_sample_model(model, sample_matrix.T, device)[1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/cmtcr_3n3g5bk2x49f7jdpdw0000gn/T/ipykernel_30049/2631893220.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  result2 = result.applymap(lambda x: x if x > 0.1 else 0)\n"
     ]
    }
   ],
   "source": [
    "# filter out values that are less than the threshold of 0.1\n",
    "result2 = result.applymap(lambda x: x if x > 0.1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A10A1S5NAQBT21    0.011993\n",
       "A11GO5VA74HD8K    0.010153\n",
       "A12A08OL0TZY0W    0.019975\n",
       "A13F2IV3ME23R     0.044718\n",
       "A14OJS0VWMOSWO    0.020910\n",
       "                    ...   \n",
       "AUM3YMZ0YRJE0     0.016829\n",
       "AVXXGV0UD721E     0.011293\n",
       "AW1D2TDTE17QL     0.020270\n",
       "AWLFVCT9128JV     0.013132\n",
       "AYHVXPT15XU66     0.014390\n",
       "Name: B00086PL00, Length: 155, dtype: float32"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows and columns that are not zero\n",
    "result['B00086PL00'][result['B00086PL00'] > 0.01]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
