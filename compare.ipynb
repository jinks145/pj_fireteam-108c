{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import AutoEncoder\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sample(tensor: torch.Tensor, mask_fraction: float, device: torch.device):\n",
    "    tensor = tensor.to(device)\n",
    "    masked_tensor = tensor.clone()\n",
    "\n",
    "    # Identify non-zero elements in the tensor\n",
    "    non_zero_indices = (tensor != 0).nonzero(as_tuple=False)\n",
    "\n",
    "    # Determine the number of elements to mask\n",
    "    num_non_zeros = non_zero_indices.size(0)\n",
    "    num_to_mask = int(mask_fraction * num_non_zeros)\n",
    "\n",
    "    if num_to_mask > 0:\n",
    "        # Randomly select indices to mask\n",
    "        mask_indices = torch.randperm(num_non_zeros)[:num_to_mask]\n",
    "\n",
    "        # Apply the mask\n",
    "        masked_tensor[non_zero_indices[mask_indices, 0], non_zero_indices[mask_indices, 1]] = 0\n",
    "\n",
    "    return masked_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_sample_model\u001b[39m(model: \u001b[43mAutoEncoder\u001b[49m, masked_test, sample:pd\u001b[38;5;241m.\u001b[39mDataFrame, device: torch\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m     sample_coo \u001b[38;5;241m=\u001b[39m coo_matrix(sample\u001b[38;5;241m.\u001b[39mvalues)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "def test_sample_model(model: AutoEncoder, masked_test, sample:pd.DataFrame, device: torch.device):\n",
    "    model.eval()\n",
    "    sample_coo = coo_matrix(sample.values)\n",
    "    \n",
    "    # Convert the COO matrix to a dense tensor\n",
    "    sample_tensor = torch.tensor(sample_coo.toarray(), dtype=torch.float32, device=device)\n",
    "\n",
    "    \n",
    "    # Test the model on each row of the sample\n",
    "    # tested = sample.apply(lambda row: mask_test_model(model, 0.2, torch.tensor(row.to_numpy(), dtype=torch.float32, device=device), device)[0], axis=1)\n",
    "    masked_test = mask_sample(sample_tensor, 0.2, device)\n",
    "    \n",
    "\n",
    "    tested_df = pd.DataFrame(index=sample.index, columns=sample.columns)\n",
    "\n",
    "    result = model(masked_test)\n",
    "\n",
    "    for i, j in zip(sample_coo.row, sample_coo.col):\n",
    "        tested_df.iloc[i, j] = result[i, j].item()\n",
    "\n",
    "    # Calculate the Frobenius norm of the difference\n",
    "    # calculate the rmse\n",
    "    \n",
    "    # loss = linalg.norm(sample.to_numpy() - tested.to_numpy().T, ord='fro')\n",
    "    mse = np.mean((sample.to_numpy() - result.cpu().detach().numpy())**2)\n",
    "    loss = np.sqrt(mse)\n",
    "    \n",
    "    return loss, tested_df.T, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a user-item interaction matrix (100 users, 50 items) with sparsity\n",
    "num_users = 10000\n",
    "num_items = 500\n",
    "interaction_matrix = np.random.randint(0, 6, size=(num_users, num_items))  # Random interactions from 0 to 5\n",
    "\n",
    "# Introduce sparsity by setting a high percentage of interactions to 0\n",
    "sparsity = 0.8  # 80% of the interactions will be set to 0\n",
    "mask = np.random.rand(*interaction_matrix.shape) < sparsity\n",
    "interaction_matrix[mask] = 0\n",
    "interaction_matrix = pd.DataFrame(interaction_matrix, index=range(interaction_matrix.shape[0]), columns=range(interaction_matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo = coo_matrix(interaction_matrix, (num_users, num_items))\n",
    "dense_matrix = torch.tensor(coo.toarray(), dtype=torch.float32).to(device)\n",
    "dataset = TensorDataset(dense_matrix)\n",
    "bottleneck_size = 32\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(coo.shape[1], bottleneck_size, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 1.6104\n",
      "Epoch [2/1000], Loss: 1.5616\n",
      "Epoch [3/1000], Loss: 1.5416\n",
      "Epoch [4/1000], Loss: 1.5242\n",
      "Epoch [5/1000], Loss: 1.5112\n",
      "Epoch [6/1000], Loss: 1.5018\n",
      "Epoch [7/1000], Loss: 1.4950\n",
      "Epoch [8/1000], Loss: 1.4901\n",
      "Epoch [9/1000], Loss: 1.4873\n",
      "Epoch [10/1000], Loss: 1.4827\n",
      "Epoch [11/1000], Loss: 1.4786\n",
      "Epoch [12/1000], Loss: 1.4764\n",
      "Epoch [13/1000], Loss: 1.4720\n",
      "Epoch [14/1000], Loss: 1.4681\n",
      "Epoch [15/1000], Loss: 1.4650\n",
      "Epoch [16/1000], Loss: 1.4621\n",
      "Epoch [17/1000], Loss: 1.4599\n",
      "Epoch [18/1000], Loss: 1.4576\n",
      "Epoch [19/1000], Loss: 1.4567\n",
      "Epoch [20/1000], Loss: 1.4556\n",
      "Epoch [21/1000], Loss: 1.4549\n",
      "Epoch [22/1000], Loss: 1.4538\n",
      "Epoch [23/1000], Loss: 1.4534\n",
      "Epoch [24/1000], Loss: 1.4526\n",
      "Epoch [25/1000], Loss: 1.4526\n",
      "Epoch [26/1000], Loss: 1.4519\n",
      "Epoch [27/1000], Loss: 1.4514\n",
      "Epoch [28/1000], Loss: 1.4507\n",
      "Epoch [29/1000], Loss: 1.4504\n",
      "Epoch [30/1000], Loss: 1.4504\n",
      "Epoch [31/1000], Loss: 1.4476\n",
      "Epoch [32/1000], Loss: 1.4463\n",
      "Epoch [33/1000], Loss: 1.4457\n",
      "Epoch [34/1000], Loss: 1.4448\n",
      "Epoch [35/1000], Loss: 1.4451\n",
      "Epoch [36/1000], Loss: 1.4443\n",
      "Epoch [37/1000], Loss: 1.4431\n",
      "Epoch [38/1000], Loss: 1.4434\n",
      "Epoch [39/1000], Loss: 1.4431\n",
      "Epoch [40/1000], Loss: 1.4424\n",
      "Epoch [41/1000], Loss: 1.4423\n",
      "Epoch [42/1000], Loss: 1.4408\n",
      "Epoch [43/1000], Loss: 1.4411\n",
      "Epoch [44/1000], Loss: 1.4418\n",
      "Epoch [45/1000], Loss: 1.4409\n",
      "Epoch [46/1000], Loss: 1.4398\n",
      "Epoch [47/1000], Loss: 1.4393\n",
      "Epoch [48/1000], Loss: 1.4398\n",
      "Epoch [49/1000], Loss: 1.4387\n",
      "Epoch [50/1000], Loss: 1.4385\n",
      "Epoch [51/1000], Loss: 1.4376\n",
      "Epoch [52/1000], Loss: 1.4366\n",
      "Epoch [53/1000], Loss: 1.4378\n",
      "Epoch [54/1000], Loss: 1.4360\n",
      "Epoch [55/1000], Loss: 1.4364\n",
      "Epoch [56/1000], Loss: 1.4365\n",
      "Epoch [57/1000], Loss: 1.4357\n",
      "Epoch [58/1000], Loss: 1.4354\n",
      "Epoch [59/1000], Loss: 1.4357\n",
      "Epoch [60/1000], Loss: 1.4338\n",
      "Epoch [61/1000], Loss: 1.4335\n",
      "Epoch [62/1000], Loss: 1.4344\n",
      "Epoch [63/1000], Loss: 1.4333\n",
      "Epoch [64/1000], Loss: 1.4336\n",
      "Epoch [65/1000], Loss: 1.4323\n",
      "Epoch [66/1000], Loss: 1.4317\n",
      "Epoch [67/1000], Loss: 1.4305\n",
      "Epoch [68/1000], Loss: 1.4313\n",
      "Epoch [69/1000], Loss: 1.4315\n",
      "Epoch [70/1000], Loss: 1.4305\n",
      "Epoch [71/1000], Loss: 1.4303\n",
      "Epoch [72/1000], Loss: 1.4313\n",
      "Epoch [73/1000], Loss: 1.4299\n",
      "Epoch [74/1000], Loss: 1.4298\n",
      "Epoch [75/1000], Loss: 1.4287\n",
      "Epoch [76/1000], Loss: 1.4290\n",
      "Epoch [77/1000], Loss: 1.4283\n",
      "Epoch [78/1000], Loss: 1.4271\n",
      "Epoch [79/1000], Loss: 1.4284\n",
      "Epoch [80/1000], Loss: 1.4282\n",
      "Epoch [81/1000], Loss: 1.4270\n",
      "Epoch [82/1000], Loss: 1.4277\n",
      "Epoch [83/1000], Loss: 1.4284\n",
      "Epoch [84/1000], Loss: 1.4263\n",
      "Epoch [85/1000], Loss: 1.4262\n",
      "Epoch [86/1000], Loss: 1.4260\n",
      "Epoch [87/1000], Loss: 1.4254\n",
      "Epoch [88/1000], Loss: 1.4255\n",
      "Epoch [89/1000], Loss: 1.4251\n",
      "Epoch [90/1000], Loss: 1.4249\n",
      "Epoch [91/1000], Loss: 1.4244\n",
      "Epoch [92/1000], Loss: 1.4246\n",
      "Epoch [93/1000], Loss: 1.4241\n",
      "Epoch [94/1000], Loss: 1.4237\n",
      "Epoch [95/1000], Loss: 1.4232\n",
      "Epoch [96/1000], Loss: 1.4230\n",
      "Epoch [97/1000], Loss: 1.4214\n",
      "Epoch [98/1000], Loss: 1.4221\n",
      "Epoch [99/1000], Loss: 1.4229\n",
      "Epoch [100/1000], Loss: 1.4220\n",
      "Epoch [101/1000], Loss: 1.4209\n",
      "Epoch [102/1000], Loss: 1.4219\n",
      "Epoch [103/1000], Loss: 1.4211\n",
      "Epoch [104/1000], Loss: 1.4203\n",
      "Epoch [105/1000], Loss: 1.4205\n",
      "Epoch [106/1000], Loss: 1.4199\n",
      "Epoch [107/1000], Loss: 1.4194\n",
      "Epoch [108/1000], Loss: 1.4196\n",
      "Epoch [109/1000], Loss: 1.4193\n",
      "Epoch [110/1000], Loss: 1.4180\n",
      "Epoch [111/1000], Loss: 1.4181\n",
      "Epoch [112/1000], Loss: 1.4183\n",
      "Epoch [113/1000], Loss: 1.4177\n",
      "Epoch [114/1000], Loss: 1.4173\n",
      "Epoch [115/1000], Loss: 1.4181\n",
      "Epoch [116/1000], Loss: 1.4179\n",
      "Epoch [117/1000], Loss: 1.4170\n",
      "Epoch [118/1000], Loss: 1.4177\n",
      "Epoch [119/1000], Loss: 1.4162\n",
      "Epoch [120/1000], Loss: 1.4155\n",
      "Epoch [121/1000], Loss: 1.4169\n",
      "Epoch [122/1000], Loss: 1.4152\n",
      "Epoch [123/1000], Loss: 1.4149\n",
      "Epoch [124/1000], Loss: 1.4138\n",
      "Epoch [125/1000], Loss: 1.4146\n",
      "Epoch [126/1000], Loss: 1.4140\n",
      "Epoch [127/1000], Loss: 1.4148\n",
      "Epoch [128/1000], Loss: 1.4139\n",
      "Epoch [129/1000], Loss: 1.4136\n",
      "Epoch [130/1000], Loss: 1.4134\n",
      "Epoch [131/1000], Loss: 1.4136\n",
      "Epoch [132/1000], Loss: 1.4141\n",
      "Epoch [133/1000], Loss: 1.4137\n",
      "Epoch [134/1000], Loss: 1.4125\n",
      "Epoch [135/1000], Loss: 1.4128\n",
      "Epoch [136/1000], Loss: 1.4130\n",
      "Epoch [137/1000], Loss: 1.4128\n",
      "Epoch [138/1000], Loss: 1.4117\n",
      "Epoch [139/1000], Loss: 1.4113\n",
      "Epoch [140/1000], Loss: 1.4123\n",
      "Epoch [141/1000], Loss: 1.4116\n",
      "Epoch [142/1000], Loss: 1.4107\n",
      "Epoch [143/1000], Loss: 1.4115\n",
      "Epoch [144/1000], Loss: 1.4109\n",
      "Epoch [145/1000], Loss: 1.4101\n",
      "Epoch [146/1000], Loss: 1.4105\n",
      "Epoch [147/1000], Loss: 1.4104\n",
      "Epoch [148/1000], Loss: 1.4107\n",
      "Epoch [149/1000], Loss: 1.4099\n",
      "Epoch [150/1000], Loss: 1.4096\n",
      "Epoch [151/1000], Loss: 1.4092\n",
      "Epoch [152/1000], Loss: 1.4097\n",
      "Epoch [153/1000], Loss: 1.4091\n",
      "Epoch [154/1000], Loss: 1.4080\n",
      "Epoch [155/1000], Loss: 1.4092\n",
      "Epoch [156/1000], Loss: 1.4089\n",
      "Epoch [157/1000], Loss: 1.4088\n",
      "Epoch [158/1000], Loss: 1.4086\n",
      "Epoch [159/1000], Loss: 1.4083\n",
      "Epoch [160/1000], Loss: 1.4081\n",
      "Epoch [161/1000], Loss: 1.4080\n",
      "Epoch [162/1000], Loss: 1.4074\n",
      "Epoch [163/1000], Loss: 1.4067\n",
      "Epoch [164/1000], Loss: 1.4068\n",
      "Epoch [165/1000], Loss: 1.4071\n",
      "Epoch [166/1000], Loss: 1.4066\n",
      "Epoch [167/1000], Loss: 1.4071\n",
      "Epoch [168/1000], Loss: 1.4059\n",
      "Epoch [169/1000], Loss: 1.4071\n",
      "Epoch [170/1000], Loss: 1.4063\n",
      "Epoch [171/1000], Loss: 1.4065\n",
      "Epoch [172/1000], Loss: 1.4063\n",
      "Epoch [173/1000], Loss: 1.4055\n",
      "Epoch [174/1000], Loss: 1.4058\n",
      "Epoch [175/1000], Loss: 1.4051\n",
      "Epoch [176/1000], Loss: 1.4055\n",
      "Epoch [177/1000], Loss: 1.4053\n",
      "Epoch [178/1000], Loss: 1.4049\n",
      "Epoch [179/1000], Loss: 1.4051\n",
      "Epoch [180/1000], Loss: 1.4054\n",
      "Epoch [181/1000], Loss: 1.4042\n",
      "Epoch [182/1000], Loss: 1.4038\n",
      "Epoch [183/1000], Loss: 1.4044\n",
      "Epoch [184/1000], Loss: 1.4041\n",
      "Epoch [185/1000], Loss: 1.4040\n",
      "Epoch [186/1000], Loss: 1.4042\n",
      "Epoch [187/1000], Loss: 1.4041\n",
      "Epoch [188/1000], Loss: 1.4038\n",
      "Epoch [189/1000], Loss: 1.4033\n",
      "Epoch [190/1000], Loss: 1.4027\n",
      "Epoch [191/1000], Loss: 1.4032\n",
      "Epoch [192/1000], Loss: 1.4025\n",
      "Epoch [193/1000], Loss: 1.4027\n",
      "Epoch [194/1000], Loss: 1.4030\n",
      "Epoch [195/1000], Loss: 1.4025\n",
      "Epoch [196/1000], Loss: 1.4034\n",
      "Epoch [197/1000], Loss: 1.4022\n",
      "Epoch [198/1000], Loss: 1.4024\n",
      "Epoch [199/1000], Loss: 1.4024\n",
      "Epoch [200/1000], Loss: 1.4023\n",
      "Epoch [201/1000], Loss: 1.4009\n",
      "Epoch [202/1000], Loss: 1.4016\n",
      "Epoch [203/1000], Loss: 1.4019\n",
      "Epoch [204/1000], Loss: 1.4007\n",
      "Epoch [205/1000], Loss: 1.4017\n",
      "Epoch [206/1000], Loss: 1.4022\n",
      "Epoch [207/1000], Loss: 1.4017\n",
      "Epoch [208/1000], Loss: 1.4009\n",
      "Epoch [209/1000], Loss: 1.4015\n",
      "Epoch [210/1000], Loss: 1.4015\n",
      "Epoch [211/1000], Loss: 1.4010\n",
      "Epoch [212/1000], Loss: 1.4004\n",
      "Epoch [213/1000], Loss: 1.4005\n",
      "Epoch [214/1000], Loss: 1.4003\n",
      "Epoch [215/1000], Loss: 1.4008\n",
      "Epoch [216/1000], Loss: 1.4010\n",
      "Epoch [217/1000], Loss: 1.4001\n",
      "Epoch [218/1000], Loss: 1.4000\n",
      "Epoch [219/1000], Loss: 1.4002\n",
      "Epoch [220/1000], Loss: 1.3991\n",
      "Epoch [221/1000], Loss: 1.3996\n",
      "Epoch [222/1000], Loss: 1.3988\n",
      "Epoch [223/1000], Loss: 1.3995\n",
      "Epoch [224/1000], Loss: 1.3994\n",
      "Epoch [225/1000], Loss: 1.3993\n",
      "Epoch [226/1000], Loss: 1.3986\n",
      "Epoch [227/1000], Loss: 1.3988\n",
      "Epoch [228/1000], Loss: 1.3987\n",
      "Epoch [229/1000], Loss: 1.3991\n",
      "Epoch [230/1000], Loss: 1.3983\n",
      "Epoch [231/1000], Loss: 1.3987\n",
      "Epoch [232/1000], Loss: 1.3979\n",
      "Epoch [233/1000], Loss: 1.3979\n",
      "Epoch [234/1000], Loss: 1.3980\n",
      "Epoch [235/1000], Loss: 1.3978\n",
      "Epoch [236/1000], Loss: 1.3974\n",
      "Epoch [237/1000], Loss: 1.3969\n",
      "Epoch [238/1000], Loss: 1.3974\n",
      "Epoch [239/1000], Loss: 1.3976\n",
      "Epoch [240/1000], Loss: 1.3976\n",
      "Epoch [241/1000], Loss: 1.3973\n",
      "Epoch [242/1000], Loss: 1.3964\n",
      "Epoch [243/1000], Loss: 1.3968\n",
      "Epoch [244/1000], Loss: 1.3963\n",
      "Epoch [245/1000], Loss: 1.3969\n",
      "Epoch [246/1000], Loss: 1.3965\n",
      "Epoch [247/1000], Loss: 1.3961\n",
      "Epoch [248/1000], Loss: 1.3962\n",
      "Epoch [249/1000], Loss: 1.3958\n",
      "Epoch [250/1000], Loss: 1.3965\n",
      "Epoch [251/1000], Loss: 1.3947\n",
      "Epoch [252/1000], Loss: 1.3958\n",
      "Epoch [253/1000], Loss: 1.3952\n",
      "Epoch [254/1000], Loss: 1.3951\n",
      "Epoch [255/1000], Loss: 1.3950\n",
      "Epoch [256/1000], Loss: 1.3944\n",
      "Epoch [257/1000], Loss: 1.3954\n",
      "Epoch [258/1000], Loss: 1.3949\n",
      "Epoch [259/1000], Loss: 1.3946\n",
      "Epoch [260/1000], Loss: 1.3946\n",
      "Epoch [261/1000], Loss: 1.3942\n",
      "Epoch [262/1000], Loss: 1.3948\n",
      "Epoch [263/1000], Loss: 1.3944\n",
      "Epoch [264/1000], Loss: 1.3935\n",
      "Epoch [265/1000], Loss: 1.3933\n",
      "Epoch [266/1000], Loss: 1.3936\n",
      "Epoch [267/1000], Loss: 1.3941\n",
      "Epoch [268/1000], Loss: 1.3938\n",
      "Epoch [269/1000], Loss: 1.3931\n",
      "Epoch [270/1000], Loss: 1.3933\n",
      "Epoch [271/1000], Loss: 1.3938\n",
      "Epoch [272/1000], Loss: 1.3926\n",
      "Epoch [273/1000], Loss: 1.3941\n",
      "Epoch [274/1000], Loss: 1.3931\n",
      "Epoch [275/1000], Loss: 1.3924\n",
      "Epoch [276/1000], Loss: 1.3936\n",
      "Epoch [277/1000], Loss: 1.3928\n",
      "Epoch [278/1000], Loss: 1.3931\n",
      "Epoch [279/1000], Loss: 1.3926\n",
      "Epoch [280/1000], Loss: 1.3922\n",
      "Epoch [281/1000], Loss: 1.3924\n",
      "Epoch [282/1000], Loss: 1.3916\n",
      "Epoch [283/1000], Loss: 1.3912\n",
      "Epoch [284/1000], Loss: 1.3911\n",
      "Epoch [285/1000], Loss: 1.3906\n",
      "Epoch [286/1000], Loss: 1.3909\n",
      "Epoch [287/1000], Loss: 1.3917\n",
      "Epoch [288/1000], Loss: 1.3912\n",
      "Epoch [289/1000], Loss: 1.3904\n",
      "Epoch [290/1000], Loss: 1.3906\n",
      "Epoch [291/1000], Loss: 1.3907\n",
      "Epoch [292/1000], Loss: 1.3911\n",
      "Epoch [293/1000], Loss: 1.3912\n",
      "Epoch [294/1000], Loss: 1.3912\n",
      "Epoch [295/1000], Loss: 1.3899\n",
      "Epoch [296/1000], Loss: 1.3903\n",
      "Epoch [297/1000], Loss: 1.3903\n",
      "Epoch [298/1000], Loss: 1.3900\n",
      "Epoch [299/1000], Loss: 1.3903\n",
      "Epoch [300/1000], Loss: 1.3903\n",
      "Epoch [301/1000], Loss: 1.3894\n",
      "Epoch [302/1000], Loss: 1.3905\n",
      "Epoch [303/1000], Loss: 1.3903\n",
      "Epoch [304/1000], Loss: 1.3894\n",
      "Epoch [305/1000], Loss: 1.3897\n",
      "Epoch [306/1000], Loss: 1.3895\n",
      "Epoch [307/1000], Loss: 1.3890\n",
      "Epoch [308/1000], Loss: 1.3897\n",
      "Epoch [309/1000], Loss: 1.3893\n",
      "Epoch [310/1000], Loss: 1.3889\n",
      "Epoch [311/1000], Loss: 1.3894\n",
      "Epoch [312/1000], Loss: 1.3881\n",
      "Epoch [313/1000], Loss: 1.3887\n",
      "Epoch [314/1000], Loss: 1.3887\n",
      "Epoch [315/1000], Loss: 1.3897\n",
      "Epoch [316/1000], Loss: 1.3887\n",
      "Epoch [317/1000], Loss: 1.3887\n",
      "Epoch [318/1000], Loss: 1.3884\n",
      "Epoch [319/1000], Loss: 1.3878\n",
      "Epoch [320/1000], Loss: 1.3891\n",
      "Epoch [321/1000], Loss: 1.3882\n",
      "Epoch [322/1000], Loss: 1.3880\n",
      "Epoch [323/1000], Loss: 1.3875\n",
      "Epoch [324/1000], Loss: 1.3877\n",
      "Epoch [325/1000], Loss: 1.3876\n",
      "Epoch [326/1000], Loss: 1.3884\n",
      "Epoch [327/1000], Loss: 1.3880\n",
      "Epoch [328/1000], Loss: 1.3879\n",
      "Epoch [329/1000], Loss: 1.3875\n",
      "Epoch [330/1000], Loss: 1.3878\n",
      "Epoch [331/1000], Loss: 1.3872\n",
      "Epoch [332/1000], Loss: 1.3878\n",
      "Epoch [333/1000], Loss: 1.3881\n",
      "Epoch [334/1000], Loss: 1.3876\n",
      "Epoch [335/1000], Loss: 1.3867\n",
      "Epoch [336/1000], Loss: 1.3867\n",
      "Epoch [337/1000], Loss: 1.3864\n",
      "Epoch [338/1000], Loss: 1.3878\n",
      "Epoch [339/1000], Loss: 1.3871\n",
      "Epoch [340/1000], Loss: 1.3856\n",
      "Epoch [341/1000], Loss: 1.3864\n",
      "Epoch [342/1000], Loss: 1.3859\n",
      "Epoch [343/1000], Loss: 1.3856\n",
      "Epoch [344/1000], Loss: 1.3858\n",
      "Epoch [345/1000], Loss: 1.3864\n",
      "Epoch [346/1000], Loss: 1.3864\n",
      "Epoch [347/1000], Loss: 1.3861\n",
      "Epoch [348/1000], Loss: 1.3860\n",
      "Epoch [349/1000], Loss: 1.3866\n",
      "Early stopping at epoch 350 with loss 1.3857\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs, epoch_losses = model.fit(train_loader, n_epochs=1000, lr=0.001, patience=10)\n",
    "\n",
    "# Plot the training loss over epochs\n",
    "plt.plot(epochs, epoch_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652444</td>\n",
       "      <td>0.359875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.765655</td>\n",
       "      <td>0.794303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.423617</td>\n",
       "      <td>0.670599</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.378193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.402952</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.183549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111399</td>\n",
       "      <td>0.690187</td>\n",
       "      <td>0.310016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.316049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.423112</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.369305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.154145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.789478</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.269203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537992</td>\n",
       "      <td>0.614078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.343436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.091966</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725932</td>\n",
       "      <td>0.729194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.951135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.914785</td>\n",
       "      <td>0.456701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.051734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5    6     \\\n",
       "0    0.722846       NaN       NaN       NaN       NaN       NaN  NaN   \n",
       "1         NaN   0.79467       NaN  0.765655  0.794303       NaN  NaN   \n",
       "2         NaN       NaN       NaN  0.300264       NaN       NaN  NaN   \n",
       "3         NaN       NaN       NaN       NaN       NaN       NaN  NaN   \n",
       "4         NaN       NaN       NaN       NaN       NaN       NaN  NaN   \n",
       "..        ...       ...       ...       ...       ...       ...  ...   \n",
       "495       NaN  0.471794       NaN       NaN       NaN       NaN  NaN   \n",
       "496       NaN  0.643406       NaN       NaN       NaN       NaN  NaN   \n",
       "497       NaN       NaN       NaN  1.154145       NaN       NaN  NaN   \n",
       "498       NaN       NaN       NaN       NaN       NaN       NaN  NaN   \n",
       "499       NaN  0.725932  0.729194       NaN       NaN  0.951135  NaN   \n",
       "\n",
       "         7         8         9     ...      9990      9991      9992  \\\n",
       "0         NaN       NaN       NaN  ...  0.622437       NaN       NaN   \n",
       "1         NaN       NaN       NaN  ...       NaN       NaN  0.632058   \n",
       "2         NaN  0.423617  0.670599  ...       NaN       NaN  0.350484   \n",
       "3         NaN  0.183549       NaN  ...       NaN       NaN  0.111399   \n",
       "4    0.253203       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "495       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "496       NaN       NaN  0.423112  ...       NaN       NaN       NaN   \n",
       "497       NaN       NaN  0.789478  ...       NaN  0.269203       NaN   \n",
       "498       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "499       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "\n",
       "         9993      9994      9995      9996      9997      9998      9999  \n",
       "0    0.632438       NaN       NaN  0.652444  0.359875       NaN       NaN  \n",
       "1         NaN       NaN  0.692446       NaN       NaN       NaN       NaN  \n",
       "2         NaN  1.378193       NaN       NaN       NaN  0.402952       NaN  \n",
       "3    0.690187  0.310016       NaN       NaN  0.142618       NaN  1.316049  \n",
       "4         NaN       NaN  0.419519       NaN       NaN       NaN  0.182937  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "495       NaN       NaN       NaN       NaN -0.016872       NaN       NaN  \n",
       "496       NaN       NaN       NaN  0.369305       NaN       NaN       NaN  \n",
       "497       NaN       NaN  0.537992  0.614078       NaN       NaN       NaN  \n",
       "498       NaN  0.343436       NaN       NaN       NaN -0.091966       NaN  \n",
       "499       NaN  0.914785  0.456701       NaN -0.051734       NaN       NaN  \n",
       "\n",
       "[500 rows x 10000 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = test_sample_model(model, interaction_matrix, device)\n",
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1981571100674724"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo = coo_matrix(interaction_matrix, (num_users, num_items))\n",
    "dense_matrix = torch.tensor(coo.toarray(), dtype=torch.float32).to(device)\n",
    "dataset = TensorDataset(dense_matrix)\n",
    "bottleneck_size = 32\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(num_items, bottleneck_size, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_data:\n",
    "\tsample = pd.read_csv('predictions.csv')\n",
    "\tres = { k: v.get([\"book_id\", \"rating\"]) for k, v in sample.groupby('user_id')}\n",
    "\tsample_matrix = pd.DataFrame(index= res.keys(), columns = sample['book_id'].unique())\n",
    "\tsample_matrix.to_csv('sample_matrix.csv.gzip', index=True, columns=sample_matrix.columns, chunksize=1000, compression='gzip')\n",
    "\tfor k, v in res.items():\n",
    "\t\tt = v.reset_index(drop=True).transpose()\n",
    "\t\tsample_matrix.loc[k][t.loc[\"book_id\"]] = t.loc[\"rating\"]\n",
    "else:\n",
    "\tsample_matrix = pd.read_csv('sample_matrix.csv.gzip', compression='gzip', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.0066\n",
      "Epoch [2/1000], Loss: 0.0064\n",
      "Epoch [3/1000], Loss: 0.0063\n",
      "Epoch [4/1000], Loss: 0.0062\n",
      "Epoch [5/1000], Loss: 0.0062\n",
      "Epoch [6/1000], Loss: 0.0061\n",
      "Epoch [7/1000], Loss: 0.0061\n",
      "Epoch [8/1000], Loss: 0.0060\n",
      "Epoch [9/1000], Loss: 0.0060\n",
      "Epoch [10/1000], Loss: 0.0060\n",
      "Epoch [11/1000], Loss: 0.0059\n",
      "Epoch [12/1000], Loss: 0.0059\n",
      "Epoch [13/1000], Loss: 0.0059\n",
      "Epoch [14/1000], Loss: 0.0059\n",
      "Epoch [15/1000], Loss: 0.0059\n",
      "Epoch [16/1000], Loss: 0.0058\n",
      "Epoch [17/1000], Loss: 0.0058\n",
      "Epoch [18/1000], Loss: 0.0058\n",
      "Epoch [19/1000], Loss: 0.0058\n",
      "Epoch [20/1000], Loss: 0.0058\n",
      "Epoch [21/1000], Loss: 0.0058\n",
      "Epoch [22/1000], Loss: 0.0058\n",
      "Epoch [23/1000], Loss: 0.0058\n",
      "Epoch [24/1000], Loss: 0.0057\n",
      "Epoch [25/1000], Loss: 0.0057\n",
      "Epoch [26/1000], Loss: 0.0057\n",
      "Epoch [27/1000], Loss: 0.0057\n",
      "Epoch [28/1000], Loss: 0.0057\n",
      "Epoch [29/1000], Loss: 0.0057\n",
      "Epoch [30/1000], Loss: 0.0057\n",
      "Epoch [31/1000], Loss: 0.0057\n",
      "Epoch [32/1000], Loss: 0.0057\n",
      "Epoch [33/1000], Loss: 0.0057\n",
      "Epoch [34/1000], Loss: 0.0057\n",
      "Epoch [35/1000], Loss: 0.0057\n",
      "Epoch [36/1000], Loss: 0.0057\n",
      "Epoch [37/1000], Loss: 0.0057\n",
      "Epoch [38/1000], Loss: 0.0057\n",
      "Epoch [39/1000], Loss: 0.0057\n",
      "Epoch [40/1000], Loss: 0.0057\n",
      "Epoch [41/1000], Loss: 0.0057\n",
      "Epoch [42/1000], Loss: 0.0057\n",
      "Epoch [43/1000], Loss: 0.0056\n",
      "Epoch [44/1000], Loss: 0.0056\n",
      "Epoch [45/1000], Loss: 0.0056\n",
      "Epoch [46/1000], Loss: 0.0056\n",
      "Epoch [47/1000], Loss: 0.0056\n",
      "Epoch [48/1000], Loss: 0.0056\n",
      "Epoch [49/1000], Loss: 0.0056\n",
      "Epoch [50/1000], Loss: 0.0056\n",
      "Epoch [51/1000], Loss: 0.0056\n",
      "Early stopping at epoch 52 with loss 0.0056\n"
     ]
    }
   ],
   "source": [
    "if not training:\n",
    "\tmodel = torch.load(f'sample_model/sample_model_k={bottleneck_size}.pt')\n",
    "\tmodel.load_state_dict(torch.load(f'sample_model/sample_model_k_weights_{bottleneck_size}.pt'))\n",
    "else:\n",
    "    \n",
    "    coo = coo_matrix(sample_matrix.T.to_numpy(), (sample_matrix.shape[1], sample_matrix.shape[0]))\n",
    "    dense_matrix = torch.tensor(coo.toarray(), dtype=torch.float32).to(device)\n",
    "    dataset = TensorDataset(dense_matrix)\n",
    "    model = AutoEncoder(coo.toarray().shape[1], bottleneck_size, device=device).to(device)\n",
    "    batch_size = 128\n",
    "    \n",
    "    batches = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    epochs, losses = model.fit(batches, n_epochs=1000, lr=0.001, patience=20)\n",
    "    \n",
    "    pd.DataFrame({\"epochs\": epochs, \"training losses\": losses}).to_csv(f'sample_model/{bottleneck_size}.csv')\n",
    "    torch.save(model, f'sample_model/sample_model_k={bottleneck_size}.pt')\n",
    "    torch.save(model.state_dict(), f'sample_model/sample_model_k_weights_{bottleneck_size}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAyKklEQVR4nO3deXwV1f3/8dcn+wYJJGwh7KuAiBgBqVXAqrhUatWqxQVtf6KttbWLWL9d7Ne2Lt8W+6VuX23RulVtq5YqdV9QUVlU1CBo2MMWAiQsIWT7/P64E3qNJCRwb25I3s/HYx6ZOTNn7uckkE/OmZkz5u6IiIhEQlysAxARkbZDSUVERCJGSUVERCJGSUVERCJGSUVERCJGSUVERCJGSUUOK2b2bzO7NNLHSutjZjea2cOxjkOaR0lFos7MdoUttWa2J2x7anPO5e6nuftfIn1sc5jZBDMrivR5WzMzm2ZmNfV+lrvMLDfWsUnrkhDrAKTtc/eMunUzWw18291fqn+cmSW4e3VLxiZf1MjP4W13P77FA5LDinoqEjN1f/Gb2Qwz2wTcb2adzOwZM9tiZtuD9bywOq+Z2beD9Wlm9qaZ/S44dpWZnXaQx/Yzs3lmttPMXjKzOw9m6MXMjgg+t9TMCszsrLB9p5vZ0uAz1pvZj4PynKCdpWa2zczeMLP9/t80s/FmttDMyoKv44PyC8xsUb1jrzWzOcF6ctD2tWa22czuMbPUhn4OB9Hu1Wb206B9283sfjNLCdv//8ysMGjfnPAejpkNN7MXg32bzeyGsFMnmdmDwfeswMzyw+rNCL6PO81suZmd1Ny4JfKUVCTWugOdgT7AFYT+Td4fbPcG9gB3NFJ/LLAcyAFuA/5sZnYQxz4KLACygRuBi5vbEDNLBP4FvAB0Bb4HPGJmQ4JD/gxMd/cOwAjglaD8R0AR0AXoBtwAfGH+JDPrDDwLzArinAk8a2bZwBxgiJkNCqvyzaBdALcCg4FRwECgJ/CLsGPr/xwOxlTgVGBA8Fk/C+KeBNwMfAPoAawBHgv2dQBeAp4DcoPYXg4751nBsVlBG+8I6g0BrgaODb6fpwKrDzJuiSR316KlxRZC//G/EqxPACqBlEaOHwVsD9t+jdDwGcA0oDBsXxqhX8bdm3MsoeRVDaSF7X8YeLiBmCYARfsp/zKwCYgLK/srcGOwvhaYDnSsV++/gX8CAw/wvbsYWFCv7G1gWljMvwjWBwE7g3YasBsYEFbvOGBVM34O04LvUWnYsqLez/XKsO3T6/YTSqa3he3LAKqAvsCFwPsNfOaNwEth28OAPcH6QKAY+AqQGOt/11r+s6inIrG2xd0r6jbMLM3M/s/M1pjZDmAekGVm8Q3U31S34u7lwWpGM4/NBbaFlQGsa2Y7CM6zzt1rw8rWEOoVAJxD6JftGjN73cyOC8r/BygEXjCzlWZ2fSPnX1OvLPz8jxL6JQ2hXsrTQZu6EEoui4MhtlJCPYMuYef53M+hAe+4e1bYMqDe/vDv2Zog3i/E7e67gK1B3L2AFY185qaw9XIgJbjmUwj8gFDiKTazx3TTQOugpCKxVn+Y50fAEGCsu3cETgjKGxrSioSNQGczSwsr63UQ59kA9Kp3PaQ3sB7A3Re6+xRCQ2NPA08E5Tvd/Ufu3h/4KvDDBq4PbCA0PBVu3/kJDbvlmNkoQsmlbuirhNAw4vCwhJDpYTdQsJ/htoMQ/j3rHcT7hbjNLJ3Q8N16QomofnJqEnd/1EM3DvQhFP+tB3MeiSwlFWltOhD6BVgaXEP4ZbQ/0N3XAIuAG80sKehBfPVA9cwsJXwhdE1mN3CdmSWa2YTgPI8F551qZpnuXgXsAGqC85xpZgOD6zt15TX7+ci5wGAz+6aZJZjZ+YSGhJ4J2lEN/J1Qz6cz8GJQXgvcB9xuZl2Dz+xpZqcexLerMd81s7zg53YD8HhQ/ihwmZmNMrNk4LfAu+6+Ooi9u5n9ILiZoIOZjT3QB5nZEDObFJyvgtC/mf19z6SFKalIa/MHIJXQX9fvEBqmaQlTCV1n2Ar8mtAvxL2NHN+T0C+y8KUXoQvLpxGK/y7gEndfFtS5GFgdDOtdCVwUlA8idLF6F6FrJHe5+2v1P9DdtwJnEurNbQWuA85095Kwwx4ldJ3hb/7524JnEBpieyf4/JcI9Qib4zj74nMqx9b77BeAlcHy6yDul4GfA/8g1CscAFwQ7NsJnEwo+W4CPgMmNiGWZOAWQt/nTYR6fzc0WkNahLnrJV0i9ZnZ48Ayd496T6ktsEaeP5L2RT0VEcDMjjWzAWYWZ2aTgSmErnuISDPoiXqRkO7Ak4QuIBcBV7n7+7ENSeTwo+EvERGJGA1/iYhIxLTr4a+cnBzv27dvrMMQETmsLF68uMTdu+xvX7tOKn379mXRokUHPlBERPYxs/ozO+yj4S8REYkYJRUREYkYJRUREYmYdn1NRURan6qqKoqKiqioONCkyRJtKSkp5OXlkZiY2OQ6Sioi0qoUFRXRoUMH+vbtS8PvW5Noc3e2bt1KUVER/fr1a3I9DX+JSKtSUVFBdna2EkqMmRnZ2dnN7jEqqYhIq6OE0joczM9BSeUgrC/dw8wXlrNm6+5YhyIi0qooqRyE0vJKZr1SSMGGHbEORUQiaOvWrYwaNYpRo0bRvXt3evbsuW+7srKy0bqLFi3immuuOeBnjB8/PiKxvvbaa5x55pkROVck6UL9QeiZlQrAhtI9MY5ERCIpOzubDz74AIAbb7yRjIwMfvzjH+/bX11dTULC/n9t5ufnk5+ff8DPmD9/fkRiba3UUzkImamJpCbGs6FUtzyKtHXTpk3jhz/8IRMnTmTGjBksWLCA8ePHc/TRRzN+/HiWL18OfL7ncOONN3L55ZczYcIE+vfvz6xZs/adLyMjY9/xEyZM4Nxzz2Xo0KFMnTqVulnj586dy9ChQzn++OO55pprmtUj+etf/8qRRx7JiBEjmDFjBgA1NTVMmzaNESNGcOSRR3L77bcDMGvWLIYNG8bIkSO54IILDv2bhXoqB8XMyM1KYWOZeioi0fSrfxWwNMLDzMNyO/LLrw5vVp1PP/2Ul156ifj4eHbs2MG8efNISEjgpZde4oYbbuAf//jHF+osW7aMV199lZ07dzJkyBCuuuqqLzzv8f7771NQUEBubi5f+tKXeOutt8jPz2f69OnMmzePfv36ceGFFzY5zg0bNjBjxgwWL15Mp06dOOWUU3j66afp1asX69ev5+OPPwagtLQUgFtuuYVVq1aRnJy8r+xQRbWnYmaTzWy5mRWa2fX72W9mNivY/6GZjW5KXTP7XrCvwMxuCysfaWZvB+UfmVlKtNqWm5Wq4S+RduK8884jPj4egLKyMs477zxGjBjBtddeS0FBwX7rnHHGGSQnJ5OTk0PXrl3ZvHnzF44ZM2YMeXl5xMXFMWrUKFavXs2yZcvo37//vmdDmpNUFi5cyIQJE+jSpQsJCQlMnTqVefPm0b9/f1auXMn3vvc9nnvuOTp27AjAyJEjmTp1Kg8//HCDw3rNFbWeipnFA3cCJxN6k95CM5vj7kvDDjsNGBQsY4G7gbGN1TWziYRe9TrS3feaWdfg8xKAh4GL3X2JmWUDVdFqX25mKp9s3Bmt04sINLtHES3p6en71n/+858zceJEnnrqKVavXs2ECRP2Wyc5OXnfenx8PNXV1U065lBenNhQ3U6dOrFkyRKef/557rzzTp544glmz57Ns88+y7x585gzZw433XQTBQUFh5xcotlTGQMUuvtKd68EHiOUDMJNAR70kHeALDPrcYC6VwG3uPteAHcvDspPAT509yVB+VZ3r4lW43KzUinZtZe91VH7CBFphcrKyujZsycADzzwQMTPP3ToUFauXMnq1asBePzxx5tcd+zYsbz++uuUlJRQU1PDX//6V0488URKSkqora3lnHPO4aabbuK9996jtraWdevWMXHiRG677TZKS0vZtWvXIccfzWsqPYF1YdtFhHojBzqm5wHqDga+bGa/ASqAH7v7wqDczex5oAvwmLvfRj1mdgVwBUDv3r0PrmVAj6zQyNqmsgr6ZKcf4GgRaSuuu+46Lr30UmbOnMmkSZMifv7U1FTuuusuJk+eTE5ODmPGjGnw2Jdffpm8vLx923/729+4+eabmThxIu7O6aefzpQpU1iyZAmXXXYZtbW1ANx8883U1NRw0UUXUVZWhrtz7bXXkpWVdegNcPeoLMB5wJ/Cti8G/ljvmGeB48O2XwaOaawu8DEwCzBCPZpVwfqPg/UcIA14GzipsRiPOeYYP1hvfrbF+8x4xucXlhz0OUTki5YuXRrrEGJu586d7u5eW1vrV111lc+cOTNmsezv5wEs8gZ+r0Zz+KsI6BW2nQdsaOIxjdUtAp4M2rYAqCWUSIqA1929xN3LgbnAaKKkR2aop6KL9SISaffddx+jRo1i+PDhlJWVMX369FiH1GTRTCoLgUFm1s/MkoALgDn1jpkDXBLcBTYOKHP3jQeo+zQwCcDMBgNJQAnwPDDSzNKCi/YnAkuJktzgAUjdViwikXbttdfywQcfsHTpUh555BHS0tJiHVKTRe2airtXm9nVhH7ZxwOz3b3AzK4M9t9DqDdxOlAIlAOXNVY3OPVsYLaZfQxUApcG3bHtZjaTUEJyYK67Pxut9qUkxpOdnsR6PQApEnHurkklWwE/iDvRovrwo7vPJZQ4wsvuCVt34LtNrRuUVwIXNVDnYUK3FbeIHnoAUiTiUlJS2Lp1q6a/jzEP3qeSktK8x/30RP0hyM1MZbVmKhaJqLy8PIqKitiyZUusQ2n36t782BxKKocgNyuV+Su2xjoMkTYlMTGxWW8alNZFE0oegtysFHbtrWZHRdQe3BcROawoqRyCHpmaAl9EJJySyiHYd1ux7gATEQGUVA5JbjBVy3r1VEREACWVQ9K1QwrxcabbikVEAkoqhyA+zujeMUVvgBQRCSipHKLcrBRdqBcRCSipHKLcrFQ2aPhLRARQUjlkPTJT2VRWQW3twb+tTUSkrVBSOUQ9s1KoqnFKdu2NdSgiIjGnpHKI6h6A1G3FIiJKKofsP+9V0R1gIiJKKoeoZ5amahERqaOkcog6piaQlhSvZ1VERFBSOWRmFrqtWD0VEREllUjokak3QIqIgJJKRPTMStW76kVEUFKJiB6ZqZTs2sve6ppYhyIiElNKKhFQNwX+Jt1WLCLtnJJKBNQ9q6IHIEWkvVNSiQC9AVJEJERJJQJ6ZIaGv3RbsYi0d0oqEZCSGE92ehIbdE1FRNo5JZUI0QOQIiJKKhGjByBFRJRUIibUU9Hwl4i0b0oqEZKblcKuvdXsqKiKdSgiIjGjpBIhuZoCX0QkuknFzCab2XIzKzSz6/ez38xsVrD/QzMb3ZS6Zva9YF+Bmd1Wb19vM9tlZj+OXsu+SElFRAQSonViM4sH7gROBoqAhWY2x92Xhh12GjAoWMYCdwNjG6trZhOBKcBId99rZl3rffTtwL+j1a6G5GbWJRVdVxGR9iuaPZUxQKG7r3T3SuAxQskg3BTgQQ95B8gysx4HqHsVcIu77wVw9+K6k5nZ14CVQEEU27VfXTokkxBn6qmISLsWzaTSE1gXtl0UlDXlmMbqDga+bGbvmtnrZnYsgJmlAzOAXzUWlJldYWaLzGzRli1bmtmkhsXHGd06puhd9SLSrkUzqdh+yryJxzRWNwHoBIwDfgI8YWZGKJnc7u67GgvK3e9193x3z+/SpUtjhzZb6L0q6qmISPsVtWsqhHoXvcK284ANTTwmqZG6RcCT7u7AAjOrBXIIXZM5N7hwnwXUmlmFu98RmeYcWI+sFN5bu72lPk5EpNWJZk9lITDIzPqZWRJwATCn3jFzgEuCu8DGAWXuvvEAdZ8GJgGY2WBCCajE3b/s7n3dvS/wB+C3LZlQIHQH2KayCmpr63fIRETah6j1VNy92syuBp4H4oHZ7l5gZlcG++8B5gKnA4VAOXBZY3WDU88GZpvZx0AlcGnQa4m53KxUqmqckl176doxJdbhiIi0uGgOf+HucwkljvCye8LWHfhuU+sG5ZXARQf43BsPItxDlhtMgb++dI+Sioi0S3qiPoLqHoAs2q6L9SLSPimpRFC/nHQ6pSXyzIf170cQEWkflFQiKCUxnm+O7c0LSzezdmt5rMMREWlxSioRdvG4vsSbcf/8VbEORUSkxSmpRFj3zBTOHNmDJxau0zT4ItLuKKlEwbeO78/uyhqeWLjuwAeLiLQhSipRcGReJmP6dub+t1ZTXVMb63BERFqMkkqUXH58P9aX7uHFpZtjHYqISItRUomSk4d1o1fnVP78pi7Yi0j7oaQSJfFxxrTx/Vi0ZjtL1pXGOhwRkRahpBJF38jPIyM5Qb0VEWk3lFSiqENKIucf24u5H21kY5mmbhGRtk9JJcqmje9LrTsPvr0m1qGIiESdkkqU9eqcxqnDu/Pou2spr6yOdTgiIlGlpNICLj++H2V7qvj74qJYhyIiElVKKi0gv08njunTiXteW8He6ppYhyMiEjVKKi3AzLjmpEFsKKtQb0VE2jQllRZywqAcRvXK4q5XV1BZralbRKRtUlJpIWbG978yiPWle/jHe+qtiEjbpKTSgiYM7sJReZnc+WohVZpoUkTaICWVFlTXWynavocn1VsRkTZISaWFTRzSlZF5mdyh3oqItEFKKi3MzLhm0iDWbdvD0++vj3U4IiIRpaQSAycd0ZXhuR2549VCvcRLRNoUJZUYqHtuZc3Wcv75wYZYhyMiEjFKKjFyyrBuHNFDvRURaVuUVGLEzPj+SQNZVbKbf32o3oqItA1KKjF0yrDuDO3egTteKaS21mMdjojIIVNSiaG4OOO7EweyYstunivYFOtwREQOmZJKjJ1+ZA/656Tzx1cKcVdvRUQOb0oqMRYfZ3xn4kA+2biDV5YVxzocEZFDEtWkYmaTzWy5mRWa2fX72W9mNivY/6GZjW5KXTP7XrCvwMxuC8pONrPFZvZR8HVSNNsWSVNG5ZLXKVW9FRE57EUtqZhZPHAncBowDLjQzIbVO+w0YFCwXAHcfaC6ZjYRmAKMdPfhwO+Cc5UAX3X3I4FLgYei1bZIS4yP46oJA/hgXSnzV2yNdTgiIgctmj2VMUChu69090rgMULJINwU4EEPeQfIMrMeB6h7FXCLu+8FcPfi4Ov77l53b24BkGJmyVFsX0Sde0we3Tom88dXPot1KCIiBy2aSaUnsC5suygoa8oxjdUdDHzZzN41s9fN7Nj9fPY5wPt1iSecmV1hZovMbNGWLVua1aBoSk6IZ/oJA3hn5TYWrt4W63BERA5KNJOK7aes/gWDho5prG4C0AkYB/wEeMLM9h1vZsOBW4Hp+wvK3e9193x3z+/SpUvjLWhhF47pTXZ6Ene8UhjrUEREDko0k0oR0CtsOw+o/+h4Q8c0VrcIeDIYMlsA1AI5AGaWBzwFXOLuKyLUjhaTmhTPt7/cn9c/3cKHRaWxDkdEpNmimVQWAoPMrJ+ZJQEXAHPqHTMHuCS4C2wcUObuGw9Q92lgEoCZDQaSgBIzywKeBX7q7m9FsV1RddG43mSmJqq3IiKHpaglFXevBq4Gngc+AZ5w9wIzu9LMrgwOmwusBAqB+4DvNFY3qDMb6G9mHxO6gH+ph+7DvRoYCPzczD4Ilq7Ral+0dEhJZNr4vrywdDPLNu2IdTgiIs1iTXkuwszSgT3uXhv0DoYC/3b3qmgHGE35+fm+aNGiWIfxBaXllXzpllcYPzCH+y7Jj3U4IiKfY2aL3X2/v5ya2lOZR+gW3Z7Ay8BlwAORCU/qy0pL4ruTBvLi0s28smxzrMMREWmypiYVc/dy4OvAH939bEIPJUqUfPv4/gzqmsEv/lnAnsqaWIcjItIkTU4qZnYcMJXQxXAI3dorUZKUEMdNXxtB0fY9eiBSRA4bTU0qPwB+CjwVXGzvD7watagEgHH9s/n66J7c98ZKCot3xjocEZEDalJScffX3f0sd7/VzOKAEne/JsqxCXDD6UeQlpTAz57+WJNNikir16SkYmaPmlnH4C6wpcByM/tJdEMTgJyMZGZMHso7K7fx1PvrYx2OiEijmjr8NczddwBfI/RsSW/g4mgFJZ93wbG9OLp3Fr959hPKyg/ru7hFpI1ralJJNLNEQknln8HzKRqLaSFxccavvzaC7eWV3Pr8sliHIyLSoKYmlf8DVgPpwDwz6wPoce8WNDw3k2nj+/HXBWt5f+32WIcjIrJfTb1QP8vde7r76cFEjmuAiVGOTer54SmD6dYhhZ8++RGV1bWxDkdE5AuaeqE+08xm1r2HxMx+T6jXIi0oIzmB35w9gmWbdjLrZT27IiKtT1OHv2YDO4FvBMsO4P5oBSUNO+mIbpx7TB53v76CJetKYx2OiMjnNDWpDHD3Xwav913p7r8C+kczMGnYz88cRtcOyfzob0uoqNIULiLSejQ1qewxs+PrNszsS8Ce6IQkB5KZmsgt54yksHgXM1/8NNbhiIjs09T5u64EHjSzzGB7O3BpdEKSpjhxcBcuHNOb+95YySnDupHft3OsQxIRafLdX0vc/ShgJDDS3Y8mePuixM5/nXEEPbNS+fHfllBeWR3rcEREmvfmR3ffETxZD/DDKMQjzZCRnMBt545k9dZybntueazDERE5pNcJW8SikIM2fkAO08b35YH5q5m/oiTW4YhIO3coSUXTtLQS100eQt/sNH74+BI2lun+CRGJnUaTipntNLMd+1l2ArktFKMcQFpSAndNPYadFVVcdv9CdlZo0kkRiY1Gk4q7d3D3jvtZOri73vzYigzL7chdFx3DZ8W7+M4j71FVo2lcRKTlHcrwl7QyJw7uwm/PHsEbn5Xws6f0Ui8RaXnqbbQx5x/bm3Xb9nDHq4X06pzK1ZMGxTokEWlHlFTaoB+dMpj1pXv43Qufktcpja8d3TPWIYlIO6Gk0gaZGbeeM5KNZXv4yd+X0LVjMuMH5MQ6LBFpB3RNpY1KSojj/y7Kp092OtMfWsyyTXqnmohEn5JKG5aZlshfLh9DelICl85eQNH28liHJCJtnJJKG9czK5W/XD6GPZU1XDJ7Adt2V8Y6JBFpw5RU2oEh3Tvwp0uPZf32PVz2wEJNPikiUaOk0k6M6deZP154NB8VlerhSBGJmqgmFTObbGbLzazQzK7fz34zs1nB/g/NbHRT6prZ94J9BWZ2W1j5T4Pjl5vZqdFs2+HolOHd+e3ZR/La8i3M+PuH1Nbq4UgRiayo3VJsZvHAncDJQBGw0MzmuPvSsMNOAwYFy1jgbmBsY3XNbCIwhdB7XfaaWdfg84YBFwDDCc1L9pKZDXZ3vW83zAVjerNl515+/+Kn5HRI5qenDcVME06LSGRE8zmVMUChu68EMLPHCCWD8KQyBXjQQ/OJvGNmWWbWA+jbSN2rgFvcfS+AuxeHneuxoHyVmRUGMbwdxTYelq6eNJCSXXu5d95K4syYMXmIEouIREQ0h796AuvCtouCsqYc01jdwcCXzexdM3vdzI5txudhZleY2SIzW7Rly5ZmNqltMDN++dXhTB3bm3teX8Fv536iecJEJCKi2VPZ35++9X9zNXRMY3UTgE7AOOBY4Akz69/Ez8Pd7wXuBcjPz2+3v0nj4oxff20ECXHGfW+sorrW+cWZw9RjEZFDEs2kUgT0CtvOAzY08ZikRuoWAU8GQ2YLzKwWyGni50kYM+PGs4aTEB/Hn99cRXWN86uzhhMXp8QiIgcnmsNfC4FBZtbPzJIIXUSfU++YOcAlwV1g44Ayd994gLpPA5MAzGwwoQRUEuy/wMySzawfoYv/C6LYvjbBzPjZGUcw/cT+PPTOGv7r6Y90V5iIHLSo9VTcvdrMrgaeB+KB2e5eYGZXBvvvAeYCpwOFQDlwWWN1g1PPBmab2cdAJXBp0GspMLMnCF3Mrwa+qzu/msbMuH7yUBLj4rjj1UKqapybv34kifF6jElEmsfa8wXa/Px8X7RoUazDaDXcnf99+TP+8NJnjOvfmTu/OZrsjORYhyUirYyZLXb3/P3t05+iso+Z8YOvDGbmN47ivbWlnHXHW3y8vizWYYnIYURJRb7g66Pz+MeV43F3zrl7Pk+9XxTrkETkMKGkIvt1ZF4mc753PKN6ZXHt40u46ZmlVGu+MBE5ACUVaVBORjIPf3ss08b35c9vruKS2QvYULon1mGJSCumpCKNSoyP48azhvM/547kvbXbOXnm6zz49mrddiwi+6WkIk1yXn4vXrz2REb36cQv/lnAuffM59PNO2Mdloi0Mkoq0mS9Oqfx4OVjuP38o1hVspszZr3BzBc/ZW+1HgcSkRAlFWkWM+Pso/N46YcncubIXGa9/Bmn/+8brNiyK9ahiUgroKQiByU7I5nbzx/FXy4fQ9meKs7/v7dZtmlHrMMSkRhTUpFDcuLgLjw+/TgS4uK44N53+LCoNNYhiUgMKanIIRvQJYMnph9HRnICU+97l0Wrt8U6JBGJESUViYje2Wk8Mf04unRI5uI/L2B+YUmsQxKRGFBSkYjJzUrlsenj6NU5lWkPLOTVZcUHriQibYqSikRU1w4pPHbFcQzulsEVDy1i9pur9KCkSDuipCIR1zk9iUe+PY7jB+bw388s5fx732ZVye5YhyUiLUBJRaIiMzWR2dOO5XfnHcWyTTuZ/Id5/OmNldSo1yLSpimpSNSYGecek8eL157I8QNz+PWzn3DePfP1oKRIG6akIlHXPTOFP12az+3nH8WKLbs5/X/f4IanPmLxmm205zePirRFUXtHvUi4uuldvjQgh1ufW86T7xXx6Ltr6ZeTzteP7snZo3uS1ykt1mGKyCHSO+r1jvqY2LW3mrkfbeQfi4t4d1XoYcnj+mdz7cmDGdOvc4yjE5HGNPaOeiUVJZWYW7etnKfeX8/jC9exaUcF1506hCtO6I+ZxTo0EdmPxpKKrqlIzPXqnMY1Jw3iuR98mVOHd+Pmfy9j+kOLKdtTFevQRKSZlFSk1eiQksid3xzNz88cxivLijnrjjcp2FAW67BEpBmUVKRVMTO+dXw/HrtiHBVVNZx913weX7g21mGJSBMpqUirlN+3M89e82WO7duJGf/4iEtmL+DVZcWa8kWkldOFel2ob9Vqap373ljJn99cxZade+ndOY2LxvXmG/m9yEpLinV4Iu2S7v5qgJLK4aOyupbnCzbx0NtrWLB6G8kJcUwZlcsVJ/RnYNcOsQ5PpF1RUmmAksrh6ZONO3jw7TU8/f56qmtruWbSIK6cMIDEeI3mirQE3VIsbcoRPTpy89eP5M0ZE5k8oge/f/FTvnbnW7pTTKQVUFKRw1Z2RjJ/vPBo7rnoGDbv2MuUO95i5gvLqayujXVoIu1WVJOKmU02s+VmVmhm1+9nv5nZrGD/h2Y2+kB1zexGM1tvZh8Ey+lBeaKZ/cXMPjKzT8zsp9Fsm7Qek0d056UfnsBZR+Uy65VCvvrHN1m4WpNVisRC1JKKmcUDdwKnAcOAC81sWL3DTgMGBcsVwN1NrHu7u48KlrlB2XlAsrsfCRwDTDezvlFpnLQ6WWlJzDx/FLOn5VO6p5Lz7nmbM//4Jo8tWEt5ZXWswxNpN6LZUxkDFLr7SnevBB4DptQ7ZgrwoIe8A2SZWY8m1q3PgXQzSwBSgUpgRwTbI4eBSUO78cqPJvCbs0dQU+tc/+RHjP3ty9w4p4DCYr3HRSTaojn1fU9gXdh2ETC2Ccf0bELdq83sEmAR8CN33w78nVDi2QikAde6+7YItEMOM+nJCUwd24dvjunN4jXbefidNTz67loemL+aY/t24uRh3fjKEd3o3yUj1qGKtDnRTCr7m2K2/iB3Q8c0Vvdu4KZg+ybg98DlhHo3NUAu0Al4w8xecveVn/tAsysIDbXRu3fvJjVEDk9mRn7fzuT37czPztzLE4vW8a8lG/nt3GX8du4y+uek85Vh3ThpaFeO6dOJBN2SLHLIoplUioBeYdt5wIYmHpPUUF1331xXaGb3Ac8Em98EnnP3KqDYzN4C8oHPJRV3vxe4F0LPqRxMw+Twk5ORzHcmDOQ7EwZStL2cV5YV8+LSzdz/1irunbeS3MwUbjxrOKcM7x7rUEUOa9H802whMMjM+plZEnABMKfeMXOAS4K7wMYBZe6+sbG6wTWXOmcDHwfra4FJwbnSgXHAsmg1Tg5feZ3SuOS4vjz0rbG89/OTufObo+mYmsgVDy3myocWs6msItYhihy2otZTcfdqM7saeB6IB2a7e4GZXRnsvweYC5wOFALlwGWN1Q1OfZuZjSI0/LUamB6U3wncTyjJGHC/u38YrfZJ29AhJZEzRvbglOHd+NMbq/jDS5/y1swSrps8hKlj+xAXpxeFiTSHpmnRNC0SZs3W3fzXUx/zZmEJo3tncfPXRzKku+YWEwmnaVpEmqhPdjoPfWsMM79xFKtKdjP5f+cx7f4FvLh0M9U1elJf5EDUU1FPRRqwbXclD7y1iscWrqN45156ZKZwwbG9Of/YXnTPTIl1eCIxo1mKG6CkIk1RVVPLy58U88i7a3jjsxLi44zxA7LJSE6g7r+PB3e8JyfEc/zAHE4e1o1O6Xrfi7RNSioNUFKR5lqzdTePLljL68u3UFPrWHAd3zDMoLS8ik07KoiPM47rn83kEd05dXh3unRIjm3gIhGkpNIAJRWJNHenYMMO5n60kec+3sTKkt2YwbF9OnPSEV2ZNLQrA7tmYKa7yuTwpaTSACUViSZ359PNu5j70UaeL9jEsk07AcjrlMqkoV2ZOKQrxw3IJiUxPsaRijSPkkoDlFSkJa0v3cNry4t5dVkxbxVuZU9VDSmJcXx9dB5XnjCA3tlpsQ5RpEmUVBqgpCKxUlFVwzsrt/Lvjzbx1PvrqXHnqyN7cNWEgXouRlo9JZUGKKlIa7B5RwV/emMlj7y7lvLKGk4Z1o3vTBzIqF5ZsQ5NZL+UVBqgpCKtyfbdlTwwfzUPzF9N2Z4qOqQkkJuZSo+sFHpkppKbmUKPrFQykuMxM+LMiI9j33p6UjxZaUl0SkskMzVRsy5L1CipNEBJRVqjXXureer99RRu3smGsgo2lO5hY1kF23ZXNus8HVMS6JSeRH6fzvzolMHkZqVGKWJpbxpLKtGc+l5EDkJGcgIXj+vzhfKKqho2llVQUVVDrTvuUOtOTa1T687uvTVsL6+ktLyKbbsrKS2vpGRXJf/6cAPPfLiB6Sf0Z/qJA0hP1n97iR796xI5TKQkxtMvJ73Z9dZtK+fW55Yx65VCHlu4jp+cOoRzRudpBmaJCg1/afhL2onFa7bx3898wpJ1pYzo2ZELx4TefFpVXUt1rVNZU0tVtZOdkcRXj8olMzUxxhFLa6VrKg1QUpH2prbWmbNkA7c+t4yNjbyMLCUxjrOOymXq2D6MzMvUDADyOUoqDVBSkfaqsrqW4p0VJMbHBYvtW/9k4w4eeXct//xgPeWVNYzo2ZGpY/tw1lG5uh4jgJJKg5RURBq2s6KKpz/YwCPvrGHZpp0kxBm9s9MY0CWDgV0z9n3t3TmNlMRQQkqIM/Vq2gEllQYoqYgcmLvz3trtvLKsmBXFu1mxZRert+6mquaLvzvMIDE+jqT4ODKSE5gwpAunH9mD4wZkk9jE52YqqmpYsq6Ud1dt491VW/lwXRn9u2Zw8hFdOXlYdwZ304Scsaak0gAlFZGDU1VTy7pt5RQW76Jo+57gIn8tVTW1VNY4VTW1bN5RwavLitldWUOntEROHd59X4IxYOvuSop37GXzjgo276xg/fY9LFqznQ/WlVJZXYsZDO3ekVG9sli6cQdL1pUC0LtzGl85ohsnD+vGmH6didddbC1OSaUBSioi0VVRVcO8T7fw7EcbeWnpZnZXhibRrKyupbber544g+G5mYzt15mx/bMZ07czmWn/uQNt844KXv6kmBeXbuKtFVuprK6lV+dULhvfj28c24sMXe9pMUoqDVBSEWk5dQlm/oqtdExJoEvHFLp1SKZbxxS6dkwmJyO5yUNku/dW88qyYv4yfzWL1mynQ0oC3xzTm0vH99XMAS1ASaUBSioih7/3127nz2+u4t8fbwLgjCN7MKpX1r4hucqaYKmupWNKIgO6ZtA/J53+XdJJS1Lv5mAoqTRASUWk7SjaXs4Db63msYXr2LW3el+5GSQFNw/sqqwm/FdebmYK/btk0KVDMgZgEGeGBfUyUxMZ0TOTET0z6ZedrlkIAkoqDVBSEWl7KqpqqKiqISkhlEjiw25zrqiqYfXW3azcspsVxbtYWbKblVt2sa28Enf2JZy6udW2lVdSWV0LhOZkG57bkSN7ZjKoWwbpyQmkJyWQmhRPelICacmhr+nB17acgDShpIi0GymJ8Q2+ojklMZ6h3TsytHvHJp2rqqaWzzbv4uP1ZXwULA+9s4a9QaJpTHpSPBkpCaQnJ5CZmkjPrFR6dU6jV6c0enVOpVenNHKzUklKaP4rCmpqnTVbd/Pp5l18unknq0p2c0yfTpx7TF7MX0+tnop6KiLSDFU1tWwqq2BPVQ3llTWU761md2UN5ZXV7N5bw+691eyqWyqq2VVZTWl5JUXb97B++x6qw257i48zBnbJYHjPjgzPzWREbkeG5XakQ0oi7k7xzr2s3VbO2q3lrN1Wzpqtu/mseBeFxbs+l9hyMpIo2VVJTkYylx/fl4vG9aFjyhfnbqutdZZu3MFry4vJzUrl66PzDup7oOGvBiipiEhLqql1Nu2oYN22ctZtK2f11t0s3bCDgg07KN65d99xPTJT2F5eSUXVfxKHGfTomMLAbh0Y0i2DQd06MKRbBwZ2zSAtKZ53Vm7j7tdXMO/TLXRITmDquD5c/qW+JMbHMe+zLbz+6RbmfVpCya7Q55x3TB7/c95RB9UOJZUGKKmISGtRvLOCgg07KFhfxootu8lOT6JPdhq9OqfRu3MaPTulkpxw4KGtj9eXcc/rK5j70Ubi4yx43w5kpSVywqAunDi4CycM7kKXDskHHauSSgOUVESkrVpdsptH3l1DalJoupyj8rIiNvuALtSLiLQzfXPS+a8zhrX45zb/tgMREZEGRDWpmNlkM1tuZoVmdv1+9puZzQr2f2hmow9U18xuNLP1ZvZBsJwetm+kmb1tZgVm9pGZpUSzfSIi8nlRG/4ys3jgTuBkoAhYaGZz3H1p2GGnAYOCZSxwNzC2CXVvd/ff1fu8BOBh4GJ3X2Jm2UBVtNonIiJfFM2eyhig0N1Xunsl8Bgwpd4xU4AHPeQdIMvMejSxbn2nAB+6+xIAd9/q7jWRbJCIiDQumkmlJ7AubLsoKGvKMQeqe3UwXDbbzDoFZYMBN7Pnzew9M7tuf0GZ2RVmtsjMFm3ZsqX5rRIRkQZFM6ns7961+vcvN3RMY3XvBgYAo4CNwO+D8gTgeGBq8PVsMzvpCydxv9fd8909v0uXLgdqg4iINEM0k0oR0CtsOw/Y0MRjGqzr7pvdvcbda4H7CA2V1Z3rdXcvcfdyYC4wGhERaTHRTCoLgUFm1s/MkoALgDn1jpkDXBLcBTYOKHP3jY3VDa651Dkb+DhYfx4YaWZpwUX7E4HwmwJERCTKonb3l7tXm9nVhH7ZxwOz3b3AzK4M9t9DqDdxOlAIlAOXNVY3OPVtZjaK0HDYamB6UGe7mc0klJAcmOvuzzYW4+LFi0vMbM0BmpIDlDSn7W2A2tw+qM3tQzTa3KehHe16mpamMLNFDU1H0Fapze2D2tw+tHSb9US9iIhEjJKKiIhEjJLKgd0b6wBiQG1uH9Tm9qFF26xrKiIiEjHqqYiISMQoqYiISMQoqTTiQFP3twXB/GnFZvZxWFlnM3vRzD4LvnZq7ByHGzPrZWavmtknwWsSvh+Ut8l2m1mKmS0wsyVBe38VlLfJ9oYzs3gze9/Mngm223SbzWx18NqPD8xsUVDWom1WUmlA2PT7pwHDgAvNrOVfoxZ9DwCT65VdD7zs7oOAl4PttqQa+JG7HwGMA74b/Gzbarv3ApPc/ShCc+ZNDmawaKvtDfd94JOw7fbQ5onuPirs2ZQWbbOSSsMOZvr9w467zwO21SueAvwlWP8L8LWWjCna3H2ju78XrO8k9EunJ2203cGrJXYFm4nB4rTR9tYxszzgDOBPYcVtus0NaNE2K6k0rClT97dV3YI52Ai+do1xPFFjZn2Bo4F3acPtDoaBPgCKgRfdvU23N/AH4DqgNqysrbfZgRfMbLGZXRGUtWibozb3VxvQlKn75TBmZhnAP4AfuPsOs/39yNuG4IV1o8wsC3jKzEbEOKSoMrMzgWJ3X2xmE2IcTkv6krtvMLOuwItmtqylA1BPpWFNmbq/rdpcNxt08LU4xvFEnJklEkooj7j7k0Fxm2+3u5cCrxG6jtaW2/sl4CwzW01o6HqSmT1M224z7l73ipBi4ClCw/gt2mYllYY1Zer+tmoOcGmwfinwzxjGEnEW6pL8GfjE3WeG7WqT7TazLkEPBTNLBb4CLKONthfA3X/q7nnu3pfQ/91X3P0i2nCbzSzdzDrUrRN6xfrHtHCb9UR9I8zsdELjsnXT7/8mthFFnpn9FZhAaHrszcAvgaeBJ4DewFrgPHevfzH/sGVmxwNvAB/xn/H2GwhdV2lz7TazkYQu0MYT+kPyCXf/bzPLpg22t75g+OvH7n5mW26zmfUn1DuB0KWNR939Ny3dZiUVERGJGA1/iYhIxCipiIhIxCipiIhIxCipiIhIxCipiIhIxCipiESZmdUEs8bWLRGb0M/M+obPMC0Sa5qmRST69rj7qFgHIdIS1FMRiZHg3Re3Bu86WWBmA4PyPmb2spl9GHztHZR3M7OngveiLDGz8cGp4s3svuBdKS8ET82LxISSikj0pdYb/jo/bN8Odx8D3EFo9gaC9QfdfSTwCDArKJ8FvB68F2U0UBCUDwLudPfhQClwTlRbI9IIPVEvEmVmtsvdM/ZTvprQy7NWBhNcbnL3bDMrAXq4e1VQvtHdc8xsC5Dn7nvDztGX0FT2g4LtGUCiu/+6BZom8gXqqYjEljew3tAx+7M3bL0GXSuVGFJSEYmt88O+vh2szyc0sy7AVODNYP1l4CrY99Ktji0VpEhT6S8akehLDd66WOc5d6+7rTjZzN4l9AfehUHZNcBsM/sJsAW4LCj/PnCvmX2LUI/kKmBjtIMXaQ5dUxGJkeCaSr67l8Q6FpFI0fCXiIhEjHoqIiISMeqpiIhIxCipiIhIxCipiIhIxCipiIhIxCipiIhIxPx/TPt9TKib1vQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_sample_model(model, sample_matrix.T, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07575808385022091"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows and columns that are not zero\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
